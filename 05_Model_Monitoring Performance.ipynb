{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38e1f9a8-9e42-4964-a363-76fb89c19de9",
   "metadata": {},
   "source": [
    "---\n",
    "**Author:** Arifa Kokab  \n",
    "**For:** AAI-540 Machine Learning Operations  \n",
    "**Institution:** University of San Diego"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0680b5c1-e864-4057-8d91-eae8a82fb69c",
   "metadata": {},
   "source": [
    "# Model Monitoring\n",
    "\n",
    "## Note on Model Provenance\n",
    "\n",
    "The facial expression analysis model was trained externally on Google Colab using a high-performance GPU, and the trained artifact was subsequently imported to AWS SageMaker for inference and deployment. We also show how to access SageMaker Batch Transform job logs in CloudWatch for monitoring and troubleshooting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4418e8b2-3811-46ba-bcc1-74ae1f9245b5",
   "metadata": {},
   "source": [
    "## Accessing SageMaker Batch Transform Logs in CloudWatch\n",
    "\n",
    "This section retrieves and displays recent SageMaker Batch Transform job logs from Amazon CloudWatch Logs.\n",
    "Accessing these logs allows for monitoring of job progress, troubleshooting errors, and auditing inference runsâ€”ensuring transparency and reliability in the model deployment workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f753d275-18a4-40f1-ab47-0eb364f8fc9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T08:27:13.970493Z",
     "iopub.status.busy": "2025-06-26T08:27:13.970173Z",
     "iopub.status.idle": "2025-06-26T08:27:13.974054Z",
     "shell.execute_reply": "2025-06-26T08:27:13.973271Z",
     "shell.execute_reply.started": "2025-06-26T08:27:13.970469Z"
    }
   },
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4ac51be-e8f2-441e-ae72-ae97e3fa3323",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-26T08:27:20.982763Z",
     "iopub.status.busy": "2025-06-26T08:27:20.982431Z",
     "iopub.status.idle": "2025-06-26T08:27:21.093722Z",
     "shell.execute_reply": "2025-06-26T08:27:21.092892Z",
     "shell.execute_reply.started": "2025-06-26T08:27:20.982738Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recent Batch Transform Job Log Streams:\n",
      "1: pytorch-inference-2025-06-26-08-18-43-515/i-022195994fcc4083d-1750926117/data-log\n",
      "2: pytorch-inference-2025-06-26-08-18-43-515/i-022195994fcc4083d-1750926117\n",
      "3: pytorch-inference-2025-06-24-02-40-35-997/i-0be436c185d0084de-1750733033/data-log\n",
      "4: pytorch-inference-2025-06-24-02-40-35-997/i-0be436c185d0084de-1750733033\n",
      "5: pytorch-inference-2025-06-24-02-15-27-050/i-0a21b480caeb3c4fe-1750731496/data-log\n",
      "\n",
      "Fetching events from log stream: pytorch-inference-2025-06-26-08-18-43-515/i-022195994fcc4083d-1750926117/data-log\n",
      "\n",
      "2025-06-26T08:24:28.404:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\n"
     ]
    }
   ],
   "source": [
    "logs_client = boto3.client('logs', region_name='us-east-1')\n",
    "\n",
    "# The SageMaker log group for batch transform jobs\n",
    "log_group = '/aws/sagemaker/TransformJobs'\n",
    "\n",
    "# List available log streams (each stream corresponds to a job)\n",
    "response = logs_client.describe_log_streams(logGroupName=log_group, orderBy='LastEventTime', descending=True, limit=5)\n",
    "\n",
    "print(\"Recent Batch Transform Job Log Streams:\")\n",
    "for i, stream in enumerate(response['logStreams']):\n",
    "    print(f\"{i+1}: {stream['logStreamName']}\")\n",
    "\n",
    "# Fetch and print last 20 log events from the most recent job\n",
    "if response['logStreams']:\n",
    "    log_stream_name = response['logStreams'][0]['logStreamName']\n",
    "    print(f\"\\nFetching events from log stream: {log_stream_name}\\n\")\n",
    "    events = logs_client.get_log_events(\n",
    "        logGroupName=log_group,\n",
    "        logStreamName=log_stream_name,\n",
    "        limit=20,\n",
    "        startFromHead=False\n",
    "    )\n",
    "    for event in events['events']:\n",
    "        print(event['message'])\n",
    "else:\n",
    "    print(\"No log streams found for recent batch transform jobs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a6cce4-3a3e-4d16-a5a1-5960d30db542",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated how to perform large-scale batch inference using SageMaker Batch Transform and how to access and interpret model monitoring logs via AWS CloudWatch.  \n",
    "Through log analysis, we identified timeout issues affecting specific input frames, highlighting the importance of robust monitoring for production ML workflows.  \n",
    "These insights underscore the value of integrating model performance checks and real-time monitoring into the MLOps pipeline, enabling prompt identification and resolution of inference bottlenecks.  \n",
    "By systematically evaluating model behavior at scale, we ensure reliability, transparency, and continuous improvement for deployed AI systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
