{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04e6f093-4d9e-45a7-9b6f-e3dd5dbba05a",
   "metadata": {},
   "source": [
    "---\n",
    "**Author:** Arifa Kokab  \n",
    "**For:** AAI-540 Machine Learning Operations  \n",
    "**Institution:** University of San Diego"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6600707c-9c06-43b8-992b-3755885297c6",
   "metadata": {},
   "source": [
    "# Model Creation & Registration for Facial Expression Analysis (MobileNetV2)\n",
    "\n",
    "## Introduction\n",
    "This notebook covers the final stage of model creation for a facial expression analysis project using MobileNetV2.  \n",
    "The model was initially trained on Google Colab using a high-performance NVIDIA A100 GPU to accelerate deep learning experiments and reduce training time.  \n",
    "After training, the model artifact was exported and imported into AWS SageMaker for packaging, registration, and deployment. \n",
    "\n",
    "## Model Training Provenance\n",
    "\n",
    "- **Training platform:** Google Colab with NVIDIA A100 GPU\n",
    "- **Reason:** Faster deep learning training\n",
    "- **Exported model:** Saved as `.tar.gz` and uploaded to S3 for AWS SageMaker registration and deployment\n",
    "\n",
    "This approach demonstrates flexibility in utilizing the best available resources for each stage of the MLOps pipeline.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a77123b-98f7-4eb5-bf81-6cd549639217",
   "metadata": {},
   "source": [
    "## 1. Setup: Import Libraries and Initialize SageMaker Session\n",
    "\n",
    "This section imports all required libraries and initializes your AWS SageMaker session, execution role, and Boto3 client to interact with SageMaker resources programmatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56039aeb-232c-47c8-bab2-6e0497f123da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker import get_execution_role\n",
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "role = get_execution_role()\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf1856b-03c5-46d9-999f-0188c9c81e69",
   "metadata": {},
   "source": [
    "## 2. Model Packaging: Define and Configure PyTorch Model\n",
    "\n",
    "Here, we define the `PyTorchModel` object with the required inference script, model artifact location, framework and Python versions, and session/role parameters. This prepares the trained MobileNetV2 model for registration and deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5fcca75-33ac-46c5-a326-e9a0cfabfd41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T04:59:25.946116Z",
     "iopub.status.busy": "2025-06-24T04:59:25.945767Z",
     "iopub.status.idle": "2025-06-24T04:59:30.256980Z",
     "shell.execute_reply": "2025-06-24T04:59:30.256095Z",
     "shell.execute_reply.started": "2025-06-24T04:59:25.946092Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "✓ Model registered in SageMaker as 'FacialExpressionAnalysisFinal'\n"
     ]
    }
   ],
   "source": [
    "model = PyTorchModel(\n",
    "    entry_point='inference.py',\n",
    "    model_data='s3://sagemaker-us-east-1-301806113644/feamodelfolder/mob_V2model.tar.gz',\n",
    "    role=role,\n",
    "    framework_version='1.9.1',\n",
    "    py_version='py38',\n",
    "    sagemaker_session=sess,\n",
    "    name=\"FacialExpressionAnalysisFinal\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11dbd8a-a75a-4f3f-97ef-f23d6900ca4e",
   "metadata": {},
   "source": [
    "## 3. Model Registration: Create SageMaker Model from Artifact\n",
    "\n",
    "We now register the packaged model with SageMaker, creating a deployable model entity in your account. This step makes the trained model available for deployment, batch inference, or further automation in SageMaker pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d15871-528e-4fa0-89a5-df752b1f000c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_model = model.create(instance_type='ml.m5.large')\n",
    "print(\"✓ Model registered in SageMaker as 'FacialExpressionAnalysisFinal'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef45e6d-3f39-4f89-a0a2-b1754524834b",
   "metadata": {},
   "source": [
    "## 4. Model Verification: Retrieve and Display Model Details\n",
    "\n",
    "To confirm successful registration, we query SageMaker for the model’s details—such as the Model ARN, container image, S3 location, and execution role. This ensures traceability and governance for downstream deployment and audit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2031e2a-47e2-47ef-8773-149d55a9534c",
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2025-06-25T19:23:22.120807Z",
     "iopub.status.busy": "2025-06-25T19:23:22.120499Z",
     "iopub.status.idle": "2025-06-25T19:23:22.519519Z",
     "shell.execute_reply": "2025-06-25T19:23:22.518871Z",
     "shell.execute_reply.started": "2025-06-25T19:23:22.120783Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 'FacialExpressionAnalysisFinal' is registered in SageMaker.\n",
      "----- Model Details -----\n",
      "Model ARN: arn:aws:sagemaker:us-east-1:301806113644:model/FacialExpressionAnalysisFinal\n",
      "Primary container image: 763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-inference:1.9.1-cpu-py38\n",
      "Model Data URL: s3://sagemaker-us-east-1-301806113644/FacialExpressionAnalysisFinal/model.tar.gz\n",
      "Execution Role ARN: arn:aws:iam::301806113644:role/LabRole\n",
      "Creation Time: 2025-06-24 04:59:30.227000+00:00\n"
     ]
    }
   ],
   "source": [
    "model_name = \"FacialExpressionAnalysisFinal\"\n",
    "sm_client = boto3.client('sagemaker')\n",
    "\n",
    "try:\n",
    "    response = sm_client.describe_model(ModelName=model_name)\n",
    "    print(f\"Model '{model_name}' is registered in SageMaker.\")\n",
    "    print(\"----- Model Details -----\")\n",
    "    print(f\"Model ARN: {response['ModelArn']}\")\n",
    "    print(f\"Primary container image: {response['PrimaryContainer']['Image']}\")\n",
    "    print(f\"Model Data URL: {response['PrimaryContainer']['ModelDataUrl']}\")\n",
    "    print(f\"Execution Role ARN: {response['ExecutionRoleArn']}\")\n",
    "    print(f\"Creation Time: {response['CreationTime']}\")\n",
    "except sm_client.exceptions.ClientError as e:\n",
    "    print(f\"Model '{model_name}' not found or not active.\")\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1258d7dd-1a89-4263-8011-3f5e718e2218",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates the packaging and registration of a production-ready MobileNetV2 facial expression analysis model in AWS SageMaker. The resulting model can now be deployed, versioned, and integrated into automated CI/CD workflows for real-world neuromarketing applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
